\documentclass{article}

\usepackage{mainstyle}

\input{\getpdflang/title.tex}
\author{Danilo J. S. Bellini}


\begin{document}

\maketitle

\input{\getpdflang/abstract.tex}
\input{pt/intro.tex}
\input{pt/prelim.tex}


\section*{Uma recorrência similar a partir do método de Newton-Raphson}

Seja $f(\alpha) = \alpha^n - x$
em que $\alpha \in \mathds{R}$ e $x, n \in \mathds{N}^*$.
Nota-se que $f(\sqrt[n]{x}) = 0$,
e nosso objetivo é obter esse zero dessa função.
A derivada de $f$ com relação a $\alpha$ é:
\[f'(\alpha) = n \alpha^{n-1}\]
A qual é estritamente positiva para $\alpha$ positivo,
o que significa que $f(\alpha)$ é monotônica crescente
no domínio $\alpha > 0$.
Isso nos diz que a raiz $n$-ésima de $x$
é o único zero real positivo dessa função.

A regra de iteração do método de Newton-Raphson
sobre uma função $f:\mathds{R}\to\mathds{R}$
consiste no uso da raiz (ou zero)
da aproximação linear em torno do ``ponto atual'' da função
como a nova abscissa que será utilizada
para obter o ``ponto seguinte'' da sequência.
Esse processo está ilustrado na figura~\ref{fig:newton-raphson}.

\begin{figure}[H]
  \centering
  \input{newton_raphson_tikz.tex}
  \caption{Ilustração do método de Newton-Raphson}
  \label{fig:newton-raphson}
\end{figure}

A aproximação linear\footnote{
  Essa equação é dada na forma $g - g_0 = m (\alpha - \alpha_0)$,
  ou, equivalentemente,
  $g(\alpha) - g(\alpha_0) = m (\alpha - \alpha_0)$,
  em que o coeficiente angular $m$ é a derivada da função $g(\alpha)$.
} em torno da abscissa $\alpha_k$
é a reta tangente à função $f(\alpha)$ nesse ponto,
e é dada por
$g(\alpha_{k+1}) - g(\alpha_k) =
 f'(\alpha_k) \left( \alpha_{k+1} - \alpha_k \right)$,
em que:
\begin{itemize}
  \item
  $g(\alpha_k) = f(\alpha_k)$, pois a aproximação linear
  passa pelo mesmo ponto $(\alpha_k, f(\alpha_k))$ da função; e
  \item
  $g(\alpha_{k+1}) = 0$,
  pois queremos o zero da aproximação linear.
\end{itemize}

Isso permite obter a recorrência
que define a sequência do método de Newton-Raphson:
\[\alpha_{k+1} = \alpha_k - \dfrac{f(\alpha_k)}{f'(\alpha_k)}\]
Aplicando os valores de $f(\alpha)$ e $f'(\alpha)$:
\[
  \begin{array}{rcl}
  \alpha_{k+1}
  &=& \alpha_k - \dfrac{\alpha_k^n - x}{n \alpha_k^{n-1}} \\[5mm]
  &=& \dfrac{\alpha_k n \alpha_k^{n-1}
    - (\alpha_k^n - x)}{n \alpha_k^{n-1}} \\[5mm]
  &=& \dfrac{n \alpha_k^n - \alpha_k^n + x}{n \alpha_k^{n-1}} \\[5mm]
  &=& \dfrac{(n-1) \alpha_k^n + x}{n \alpha_k^{n-1}} \\[5mm]
  &=& \dfrac{(n-1) \alpha_k + \dfrac{x}{\alpha_k^{n-1}}}{n}
  \end{array}
\]
Escrevendo de outra forma:
\[\delta_{k+1} = \dfrac{x}{\alpha_k^{n-1}}\]
\[\alpha_{k+1} = \dfrac{(n-1) \alpha_k + \delta_{k+1}}{n}\]
O que é bastante similar ao algoritmo proposto inicialmente,
a menos da ausência da função chão (ou piso)
que tornava os resultados intermediários naturais/inteiros,
e da ausência, até o momento, de um critério de parada.


\section*{Convergência em $\mathds{R}$ sem truncamentos intermediários}

Esse processo iterativo,
obtido a partir do método de Newton-Raphson,
converge?
Para $n = 1$, basta substituir os valores nas equações
para encontrar $\alpha_1 = x$,
isto é, o algoritmo converge em um único passo,
independente do palpite inicial $\alpha_0$.
E para $n \ge 2$?

Admitindo que $n \ge 2$ e $\alpha_k > 0$,
podemos notar, a partir das equações fornecidas
(soma, multiplicação e divisão de números positivos),
que $\alpha_{k+1} > 0$.
Por indução, sabemos que se o palpite inicial $\alpha_0$ for positivo,
a sequência inteira será formada apenas por números positivos.
Porém, podemos restringir ainda mais
os possíveis valores de $\alpha_{k+1}$.
Para isso, basta lembrar
da desigualdade das médias aritmética e geométrica:
\[
  \dfrac{(n-1) \alpha_k + \delta_{k+1}}{n} \ge
  \sqrt[n]{\alpha_k^{n-1} \delta_{k+1}}
\]
A média aritmética de $n-1$ elementos iguais a $\alpha_k$
e um único elemento $\delta_{k+1}$
é maior que a média geométrica desses mesmos elementos,
a menos que $\alpha_k = \delta_{k+1}$,
situação na qual essas médias são iguais.
Usando as definições de $\delta_{k+1}$ e $\alpha_{k+1}$,
essa mesma desigualdade pode ser escrita como:
\[\alpha_{k+1} \ge \sqrt[n]{x}\]
Isso significa que $\alpha_1 \ge \sqrt[n]{x}$
até mesmo quando $0 < \alpha_0 < \sqrt[n]{x}$,
ou, dito de outra forma,
se a sequência converge para $\alpha_0 \ge \sqrt[n]{x}$,
então ela também converge para $\alpha_0 > 0$.
Se $\alpha_0 = \sqrt[n]{x}$, não haveria o que analisar,
o problema já estaria resolvido
e a sequência se tornaria constante
($\delta_{k+1} = \alpha_{k+1} = \sqrt[n]{x}$,
 $\forall k \in \mathds{N}$).
Mesmo ampliando dessa forma
o conjunto de valores possíveis para o $\alpha_0$,
o único caso que nos interessa é quando $\alpha_0 > \sqrt[n]{x}$.

Se $\alpha_0 > \sqrt[n]{x}$,
então $\alpha_0^n > x$,
o que também pode ser escrito como:
\[\alpha_0 > \dfrac{x}{\alpha_0^{n-1}} = \delta_1\]
Pois só estamos lidando com números positivos.
Porém podemos usar essa desigualdade, $\alpha_0 > \delta_1$,
na definição do $\alpha_1$
para descobrir que $\alpha_1 < \alpha_0$:
\[
  \alpha_1 = \dfrac{(n-1) \alpha_0 + \delta_1}{n}
  < \dfrac{(n-1) \alpha_0 + \alpha_0}{n} = \alpha_0
\]
Isto é, sabemos que $\sqrt[n]{x} \le \alpha_1 < \alpha_0$.
Utilizando exatamente esse mesmo raciocínio,
sabemos que, enquanto não chegarmos ao resultado,
$\sqrt[n]{x} \le \alpha_{k+1} < \alpha_k$,
ou seja, a cada passo/iteração estamos mais próximos do resultado.
Como tal sequência é \emph{limitada} e \emph{monotônica},
sabemos que ela é \emph{convergente}.

Resta identificar
se para qualquer erro máximo tolerável $\varepsilon > 0$
existe um número finito de passos a partir do qual é garantido que
$\alpha_k - \sqrt[n]{x} < \varepsilon$
(i.e., falta mostrar que $\lim_{k\to\infty} \alpha_k = \sqrt[n]{x}$).
Lembrando que:
\[
  \begin{array}{rcl}
  \alpha_{k+1}
  &=& \dfrac{(n-1) \alpha_k + \dfrac{x}{\alpha_k^{n-1}}}{n} \\[5mm]
  &=& \dfrac{(n-1) \alpha_k}{n} + \dfrac{x}{n\alpha_k^{n-1}} \\[5mm]
  &=& \dfrac{(n-1) \alpha_k \alpha_k^{n-1} + x}
            {n\alpha_k^{n-1}} \\[5mm]
  &=& \dfrac{(n-1) \alpha_k^n + x}{n\alpha_k^{n-1}}
  \end{array}
\]
E sabendo que,
para valores grandes de $k$, $\alpha_k \approx \alpha_{k+1}$,
o que pode ser escrito de maneira mais precisa como\footnote{
  Isso é válido pois já foi mostrado que a sequência é convergente.
}:
\[\lim_{k\to\infty} \alpha_{k+1} - \alpha_k = 0\]
Ou, equivalentemente:
\[\lim_{k\to\infty} \alpha_k = \lim_{k\to\infty} \alpha_{k+1} = L\]
Podemos continuar esse equacionamento
sem explicitar os limites para evitar poluir o equacionamento,
de onde obtemos:
\[L = \dfrac{(n-1) L^n + x}{n L^{n-1}}\]
\[L n L^{n-1} = (n-1) L^n + x\]
\[\cancel{nL^n} = \cancel{nL^n} - L^n + x\]
\[L^n = x\]
O que significa\footnote{
  Essa é a única raiz real positiva do polinômio $L^n = x$.
  As $n$ raízes são da forma
  $L = e^{\frac{2\pi i m}{n}} \sqrt[n]{x}$,
  para os diferentes valores inteiros de $m$,
  em que $i$ é a unidade imaginária.
  Para $m = 0$, temos a raiz real positiva.
  Quando $n$ é par, existe uma raiz real negativa,
  obtida com o valor $m = n/2$.
  Todas as demais raízes são complexas
  (possuem uma parcela imaginária).
} que $L = \lim_{k\to\infty} \alpha_k = \sqrt[n]{x}$.

\input{pt/algo.tex}

\end{document}
