\documentclass{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[brazil]{babel}
\usepackage{ifthen}
\usepackage{indentfirst}
\usepackage[a4paper, margin=2cm, bottom=3cm]{geometry}
\usepackage{fancyhdr}
\usepackage{lastpage}
\usepackage[hidelinks]{hyperref}
\usepackage{amsmath} % \dfrac
\usepackage{amssymb} % \blacksquare
\usepackage{dsfont} % \mathds
\usepackage{minted}
\usepackage{inconsolata}
\usepackage{tikz}
\usepackage{float}
\usepackage{cancel}

\setminted{
  python3,
  autogobble,
  style=bw,
  fontsize=\fontsize{10pt}{12pt},
  frame=lines,
  framesep=2mm,
  framerule=.7pt,
}


% Redefine \section to write custom consistent titles
\let \sectionBkp = \section
\newcommand{\sectionFormatter}[1]{
    \centering\large\textbf{\textsc{#1}}}
\renewcommand{\section}[2]
    {\ifthenelse{\equal{#1}{*}}
        {\sectionBkp*{\sectionFormatter{#2}}}
        {\sectionBkp{\sectionFormatter{#2}}}
    }

% Redefine \part to write a custom leading title
\let \partBkp = \part
\newcommand{\partFormatter}[1]{
    \centering\Large\textbf{\textsc{#1}}}
\renewcommand{\part}[2]
    {\ifthenelse{\equal{#1}{*}}
        {\partBkp*{\partFormatter{#2}}}
        {\partBkp{\partFormatter{#2}}}
    }


\linespread{1.1}
\setlength{\parskip}{9pt}
\usetikzlibrary{arrows}
\everymath{\displaystyle}

\pagestyle{fancy}
\renewcommand{\headrulewidth}{1pt}
\renewcommand{\footrulewidth}{1pt}
\cfoot{\pagename~\thepage~/~\pageref{LastPage}}

\renewcommand{\thefootnote}{[\arabic{footnote}]}

\sloppy % Required to properly break URLs


\title{Algoritmo para calcular $\lfloor \sqrt[n]{x} \rfloor$
       numericamente com $x, n \in \mathds{N}^*$}
\author{Danilo J. S. Bellini}


\begin{document}

\makeatletter\part*{\@title}\hfill\@author\makeatother


\section*{Resumo}

Na PEP 572, há um algoritmo\footnote{
  \url{https://www.python.org/dev/peps/pep-0572/\#a-numeric-example}
} implementado no Python com e sem uma \emph{assignment expression}
para o cálculo da raiz $n$-ésima de $x$,
utilizando apenas inteiros (entrada, saída e valores intermediários),
sendo que o resultado final é o valor truncado da raiz desejada
no caso deste não ser inteiro.
Este documento visa explicar e justificar
o funcionamento desse algoritmo.


\section*{Descrição do algoritmo}

Sejam $x$ e $n$ valores inteiros positivos,
e $a_0 \ge \sqrt[n]{x}$ um palpite inicial, também inteiro e positivo
(por exemplo, o próprio valor $x$).
Para encontrar numericamente o valor de $\lfloor \sqrt[n]{x} \rfloor$,
calcularemos iterativamente a seguinte sequência
enquanto $a_k > d_{k+1}$:
\[d_{k+1} = \left\lfloor \dfrac{x}{a_k^{n-1}} \right\rfloor\]
\[a_{k+1} = \left\lfloor \dfrac{(n-1) a_k + d_{k+1}}{n} \right\rfloor\]
O resultado é o último valor $a_k$ encontrado nesse processo.
Isto é, o resultado é o valor de $a_r$,
em que $r$ é menor índice $k$ para o qual vale $a_k \le d_{k+1}$.

Esse algoritmo pode ser adaptado
a partir da forma\footnote{
  O uso dessa sintaxe está disponível a partir do Python 3.8.
} como consta na PEP 572
para explicitar um valor inicial padrão e ser escrito como uma função:

\begin{center}
  \begin{minipage}{7cm}
    \begin{minted}{python}
      def nth_root(x, n, a0=None):
          a = x if a0 is None else a0
          while a > (d := x // a ** (n - 1)):
              a = ((n - 1) * a + d) // n
          return a
    \end{minted}
  \end{minipage}
\end{center}


\section*{Uma recorrência similar a partir do método de Newton-Raphson}

Seja $f(\alpha) = \alpha^n - x$
em que $\alpha \in \mathds{R}$ e $x, n \in \mathds{N}^*$.
Nota-se que $f(\sqrt[n]{x}) = 0$,
e nosso objetivo é obter esse zero dessa função.
A derivada de $f$ com relação a $\alpha$ é:
\[f'(\alpha) = n \alpha^{n-1}\]
A qual é estritamente positiva para $\alpha$ positivo,
o que significa que $f(\alpha)$ é monotônica crescente
no domínio $\alpha > 0$.
Isso nos diz que a raiz $n$-ésima de $x$
é o único zero real positivo dessa função.

A regra de iteração do método de Newton-Raphson
sobre uma função $f:\mathds{R}\to\mathds{R}$
consiste no uso da raiz (ou zero)
da aproximação linear em torno do ``ponto atual'' da função
como a nova abscissa que será utilizada
para obter o ``ponto seguinte'' da sequência.
Esse processo está ilustrado na figura~\ref{fig:newton-raphson}.

\begin{figure}[H]
  \centering
  \begin{tikzpicture}[
      domain=-.5:15.3,
      scale=.7,
      samples=100,
      axis/.style={very thick, >=stealth', ->},
      grid/.style={thin, color=gray},
      func/.style={thick, color=darkgray},
      approx/.style={thin, color=gray, >=stealth', ->},
    ]

    \draw[grid, dotted, step=1] (0, 0) grid (16, 8);
    \draw[axis] (0, -.5) -- (0, 8.5) node[above] {$f(\alpha)$};
    \draw[axis] (-.5, 0) -- (16.5, 0) node[right] {$\alpha$};
    \draw[func] plot function{(x / 10) ** 5 - .2};

    \draw[grid, dashed]
      (15, 7.39375)
        -- (15, 0)
        node[below, color=black] {$\alpha_0$}
      (12.079012345679013, 2.3713259083991125)
        -- (12.079012345679013, 0)
        node[below, color=black] {$\alpha_1$}
      (9.851113126088102, 0.7277405339275622)
        -- (9.851113126088102, 0)
        node[below, color=black] {$\alpha_2$}
      (8.305626200813814, 0.1952409256907805)
        -- (8.305626200813814, 0)
        node[below, color=black] {$\alpha_3$}
      (7.485064339688552, 0.034951211574533014)
        -- (7.485064339688552, 0)
        node[below, color=black] {$\alpha_4$};

    \draw[approx, solid]
      (15, 7.39375)
        -- (12.079012345679013, 0);
    \draw[approx, solid]
      (12.079012345679013, 2.3713259083991125)
        -- (9.851113126088102, 0);
    \draw[approx, solid]
      (9.851113126088102, 0.7277405339275622)
        -- (8.305626200813814, 0);
    \draw[approx, solid]
      (8.305626200813814, 0.1952409256907805)
        -- (7.485064339688552, 0);

    \foreach \x/\xtext in {1, 2, 3, 4, 5, 6, 7, 8, 9, 10,
                           11, 12, 13, 14, 15, 16}
      \draw[shift={(\x, 0)}] (0pt, 2pt) -- (0pt, -2pt) node[below] {};
    \foreach \y in {1, 2, 3, 4, 5, 6, 7, 8}
      \draw[shift={(0, \y)}] (2pt, 0pt) -- (-2pt, 0pt) node[left] {};

  \end{tikzpicture}
  \caption{Ilustração do método de Newton-Raphson}
  \label{fig:newton-raphson}
\end{figure}

A aproximação linear\footnote{
  Essa equação é dada na forma $g - g_0 = m (\alpha - \alpha_0)$,
  ou, equivalentemente,
  $g(\alpha) - g(\alpha_0) = m (\alpha - \alpha_0)$,
  em que o coeficiente angular $m$ é a derivada da função $g(\alpha)$.
} em torno da abscissa $\alpha_k$
é a reta tangente à função $f(\alpha)$ nesse ponto,
e é dada por
$g(\alpha_{k+1}) - g(\alpha_k) =
 f'(\alpha_k) \left( \alpha_{k+1} - \alpha_k \right)$,
em que:
\begin{itemize}
  \item
  $g(\alpha_k) = f(\alpha_k)$, pois a aproximação linear
  passa pelo mesmo ponto $(\alpha_k, f(\alpha_k))$ da função; e
  \item
  $g(\alpha_{k+1}) = 0$,
  pois queremos o zero da aproximação linear.
\end{itemize}

Isso permite obter a recorrência
que define a sequência do método de Newton-Raphson:
\[\alpha_{k+1} = \alpha_k - \dfrac{f(\alpha_k)}{f'(\alpha_k)}\]
Aplicando os valores de $f(\alpha)$ e $f'(\alpha)$:
\[
  \begin{array}{rcl}
  \alpha_{k+1}
  &=& \alpha_k - \dfrac{\alpha_k^n - x}{n \alpha_k^{n-1}} \\[5mm]
  &=& \dfrac{\alpha_k n \alpha_k^{n-1}
    - (\alpha_k^n - x)}{n \alpha_k^{n-1}} \\[5mm]
  &=& \dfrac{n \alpha_k^n - \alpha_k^n + x}{n \alpha_k^{n-1}} \\[5mm]
  &=& \dfrac{(n-1) \alpha_k^n + x}{n \alpha_k^{n-1}} \\[5mm]
  &=& \dfrac{(n-1) \alpha_k + \dfrac{x}{\alpha_k^{n-1}}}{n}
  \end{array}
\]
Escrevendo de outra forma:
\[\delta_{k+1} = \dfrac{x}{\alpha_k^{n-1}}\]
\[\alpha_{k+1} = \dfrac{(n-1) \alpha_k + \delta_{k+1}}{n}\]
O que é bastante similar ao algoritmo proposto inicialmente,
a menos da ausência da função chão (ou piso)
que tornava os resultados intermediários naturais/inteiros,
e da ausência, até o momento, de um critério de parada.


\section*{Convergência em $\mathds{R}$ sem truncamentos intermediários}

Esse processo iterativo,
obtido a partir do método de Newton-Raphson,
converge?
Para $n = 1$, basta substituir os valores nas equações
para encontrar $\alpha_1 = x$,
isto é, o algoritmo converge em um único passo,
independente do palpite inicial $\alpha_0$.
E para $n \ge 2$?

Admitindo que $n \ge 2$ e $\alpha_k > 0$,
podemos notar, a partir das equações fornecidas
(soma, multiplicação e divisão de números positivos),
que $\alpha_{k+1} > 0$.
Por indução, sabemos que se o palpite inicial $\alpha_0$ for positivo,
a sequência inteira será formada apenas por números positivos.
Porém, podemos restringir ainda mais
os possíveis valores de $\alpha_{k+1}$.
Para isso, basta lembrar
da desigualdade das médias aritmética e geométrica\footnote{
  É possível provar a desigualdade
  $\sum_{i=1}^n y_i \ge n \sqrt[n]{\prod_{i=1}^n y_i}$,
  por meio de duas induções em direções opostas.
  O caso base é:
  \[
    (y_1 - y_2)^2 \ge 0
    \implies y_1^2 - 2 y_1 y_2 + y_2^2 \ge 0
    \implies y_1^2 + 2 y_1 y_2 + y_2^2 \ge 4 y_1 y_2
    \implies (y_1 + y_2)^2 \ge 4 y_1 y_2
    \implies y_1 + y_2 \ge 2 \sqrt{y_1 y_2}
  \]
  Se a desigualdade vale para $n$ elementos,
  ela também valerá para $2n$ elementos
  (prova para as potências de $2$):
  \[
    \sum_{i=1}^{2n} y_i
    = \sum_{i=1}^{n} y_i + \sum_{i=n+1}^{2n} y_i
    \ge n \left( \sqrt[n]{\prod_{i=1}^n y_i}
               + \sqrt[n]{\prod_{i=n+1}^{2n} y_i} \right)
    \ge n 2 \sqrt{ \left( \sqrt[n]{\prod_{i=1}^n y_i} \right)
                   \left( \sqrt[n]{\prod_{i=n+1}^{2n} y_i} \right) }
    = 2n \sqrt[2n]{\prod_{i=1}^{2n} y_i}
  \]
  Se tal desigualdade vale para $n$ elementos,
  ela também valerá para $n-1$ elementos.
  Considere $y_n = \dfrac{1}{n-1} \sum_{i=1}^{n-1} y_i$:
  \[
    \sum_{i=1}^{n} y_i
    = \sum_{i=1}^{n-1} y_i + \dfrac{1}{n-1} \sum_{i=1}^{n-1} y_i
    = \left( 1 + \dfrac{1}{n-1} \right) \sum_{i=1}^{n-1} y_i
    = \dfrac{n}{n-1} \sum_{i=1}^{n-1} y_i
    \ge n \sqrt[n]{\prod_{i=1}^n y_i}
    = n \sqrt[n]{\prod_{i=1}^{n-1} y_i
                 \left( \dfrac{1}{n-1} \sum_{j=1}^{n-1} y_j \right)}
  \]
  Dividindo por $n$ cada lado da desigualdade e elevando a $n$:
  \[
    \left( \dfrac{1}{n-1}
           \sum_{i=1}^{n-1} y_i \right)^{\cancelto{n-1}{n}}
    \ge \prod_{i=1}^{n-1} y_i
        \cancel{\left( \dfrac{1}{n-1} \sum_{j=1}^{n-1} y_j \right)}
    \implies
    \sum_{i=1}^{n-1} y_i \ge (n-1) \sqrt[n-1]{\prod_{i=1}^{n-1} y_i}
  \]
  \hfill$\blacksquare$
}:
\[
  \dfrac{(n-1) \alpha_k + \delta_{k+1}}{n} \ge
  \sqrt[n]{\alpha_k^{n-1} \delta_{k+1}}
\]
A média aritmética de $n-1$ elementos iguais a $\alpha_k$
e um único elemento $\delta_{k+1}$
é maior que a média geométrica desses mesmos elementos,
a menos que $\alpha_k = \delta_{k+1}$,
situação na qual essas médias são iguais.
Usando as definições de $\delta_{k+1}$ e $\alpha_{k+1}$,
essa mesma desigualdade pode ser escrita como:
\[\alpha_{k+1} \ge \sqrt[n]{x}\]
Isso significa que $\alpha_1 \ge \sqrt[n]{x}$
até mesmo quando $0 < \alpha_0 < \sqrt[n]{x}$,
ou, dito de outra forma,
se a sequência converge para $\alpha_0 \ge \sqrt[n]{x}$,
então ela também converge para $\alpha_0 > 0$.
Se $\alpha_0 = \sqrt[n]{x}$, não haveria o que analisar,
o problema já estaria resolvido
e a sequência se tornaria constante
($\delta_{k+1} = \alpha_{k+1} = \sqrt[n]{x}$,
 $\forall k \in \mathds{N}$).
Mesmo ampliando dessa forma
o conjunto de valores possíveis para o $\alpha_0$,
o único caso que nos interessa é quando $\alpha_0 > \sqrt[n]{x}$.

Se $\alpha_0 > \sqrt[n]{x}$,
então $\alpha_0^n > x$,
o que também pode ser escrito como:
\[\alpha_0 > \dfrac{x}{\alpha_0^{n-1}} = \delta_1\]
Pois só estamos lidando com números positivos.
Porém podemos usar essa desigualdade, $\alpha_0 > \delta_1$,
na definição do $\alpha_1$
para descobrir que $\alpha_1 < \alpha_0$:
\[
  \alpha_1 = \dfrac{(n-1) \alpha_0 + \delta_1}{n}
  < \dfrac{(n-1) \alpha_0 + \alpha_0}{n} = \alpha_0
\]
Isto é, sabemos que $\sqrt[n]{x} \le \alpha_1 < \alpha_0$.
Utilizando exatamente esse mesmo raciocínio,
sabemos que, enquanto não chegarmos ao resultado,
$\sqrt[n]{x} \le \alpha_{k+1} < \alpha_k$,
ou seja, a cada passo/iteração estamos mais próximos do resultado.
Como tal sequência é \emph{limitada} e \emph{monotônica},
sabemos que ela é \emph{convergente}.

Resta identificar
se para qualquer erro máximo tolerável $\varepsilon > 0$
existe um número finito de passos a partir do qual é garantido que
$\alpha_k - \sqrt[n]{x} < \varepsilon$
(i.e., falta mostrar que $\lim_{k\to\infty} \alpha_k = \sqrt[n]{x}$).
Lembrando que:
\[
  \begin{array}{rcl}
  \alpha_{k+1}
  &=& \dfrac{(n-1) \alpha_k + \dfrac{x}{\alpha_k^{n-1}}}{n} \\[5mm]
  &=& \dfrac{(n-1) \alpha_k}{n} + \dfrac{x}{n\alpha_k^{n-1}} \\[5mm]
  &=& \dfrac{(n-1) \alpha_k \alpha_k^{n-1} + x}
            {n\alpha_k^{n-1}} \\[5mm]
  &=& \dfrac{(n-1) \alpha_k^n + x}{n\alpha_k^{n-1}}
  \end{array}
\]
E sabendo que,
para valores grandes de $k$, $\alpha_k \approx \alpha_{k+1}$,
o que pode ser escrito de maneira mais precisa como\footnote{
  Isso é válido pois já foi mostrado que a sequência é convergente.
}:
\[\lim_{k\to\infty} \alpha_{k+1} - \alpha_k = 0\]
Ou, equivalentemente:
\[\lim_{k\to\infty} \alpha_k = \lim_{k\to\infty} \alpha_{k+1} = L\]
Podemos continuar esse equacionamento
sem explicitar os limites para evitar poluir o equacionamento,
de onde obtemos:
\[L = \dfrac{(n-1) L^n + x}{n L^{n-1}}\]
\[L n L^{n-1} = (n-1) L^n + x\]
\[\cancel{nL^n} = \cancel{nL^n} - L^n + x\]
\[L^n = x\]
O que significa\footnote{
  Essa é a única raiz real positiva do polinômio $L^n = x$.
  As $n$ raízes são da forma
  $L = e^{\frac{2\pi i m}{n}} \sqrt[n]{x}$,
  para os diferentes valores inteiros de $m$,
  em que $i$ é a unidade imaginária.
  Para $m = 0$, temos a raiz real positiva.
  Quando $n$ é par, existe uma raiz real negativa,
  obtida com o valor $m = n/2$.
  Todas as demais raízes são complexas
  (possuem uma parcela imaginária).
} que $L = \lim_{k\to\infty} \alpha_k = \sqrt[n]{x}$.


\end{document}
